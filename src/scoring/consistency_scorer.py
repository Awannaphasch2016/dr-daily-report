#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Consistency Scorer

Evaluates logical consistency between narrative interpretations and quantitative data.
Uses LLM-as-judge to detect inconsistencies that rule-based checks might miss.

Focus areas:
- Logical consistency: Do interpretations match quantitative data?
- Internal consistency: Are there contradictions within the narrative?
- Semantic consistency: Do qualitative terms align with quantitative thresholds?
- Temporal consistency: Are time-based claims supported by data?

Note: Does NOT validate numeric accuracy (FaithfulnessScorer handles that).
      Ignores minor rounding differences (within 2%).
"""

import logging
import os
from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
import json

logger = logging.getLogger(__name__)


@dataclass
class ConsistencyResult:
    """Result from consistency scoring"""
    overall_score: float  # 0-100
    confidence: float  # 0-100, LLM's confidence in assessment

    dimension_scores: Dict[str, float] = field(default_factory=dict)
    inconsistencies: List[str] = field(default_factory=list)
    validated_alignments: List[str] = field(default_factory=list)
    reasoning: str = ""


class ConsistencyScorer:
    """
    LLM-based consistency scorer for narrative-data alignment.

    Evaluates whether interpretations logically match the underlying data,
    without re-checking numeric accuracy (FaithfulnessScorer's job).

    Cross-validates interpretation logic from narrative against quantitative evidence.
    """

    SYSTEM_PROMPT = """‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ä‡∏¥‡∏á‡∏ï‡∏£‡∏£‡∏Å‡∏∞‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏∏‡πâ‡∏ô

‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û (qualitative interpretations) ‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì (quantitative data) ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

**‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö:**

1. **Logical Consistency (40%)**: ‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•?
   - "‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏Ç‡∏≤‡∏Ç‡∏∂‡πâ‡∏ô" ‡πÅ‡∏ï‡πà SMA_20 < SMA_50 < SMA_200 ‚Üí ‡πÑ‡∏°‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á
   - "‡πÇ‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡∏±‡∏°‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á" ‡πÅ‡∏ï‡πà RSI = 25 (oversold) ‚Üí ‡πÑ‡∏°‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á
   - "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏±‡∏ô‡∏ú‡∏ß‡∏ô‡∏™‡∏π‡∏á" ‡πÅ‡∏ï‡πà ATR = 0.5% ‚Üí ‡πÑ‡∏°‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á
   - "‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢‡πÅ‡∏£‡∏á" ‡πÅ‡∏ï‡πà volume ratio = 0.3x ‚Üí ‡πÑ‡∏°‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á

2. **Internal Consistency (30%)**: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏Å‡∏±‡∏ô‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô?
   - "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ã‡∏∑‡πâ‡∏≠‡πÅ‡∏£‡∏á... ‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏£‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á" ‚Üí ‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á
   - "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô... ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏£‡πà‡∏ß‡∏á‡∏•‡∏á" ‚Üí ‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á
   - ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏´‡∏•‡∏≤‡∏¢‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á (‡∏ã‡∏∑‡πâ‡∏≠, ‡∏Ç‡∏≤‡∏¢, ‡∏£‡∏≠ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô) ‚Üí ‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á

3. **Semantic Consistency (20%)**: ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì?
   - Uncertainty: stable (0-25), moderate (25-50), high (50-75), extreme (75-100)
   - VWAP: strong_buy (‚â•15%), buy (‚â•5%), neutral (-5 to 5%), sell (‚â§-5%), strong_sell (‚â§-15%)
   - ATR: low (<2%), moderate (2-3.5%), high (>3.5%)
   - Volume: low (<0.8x), normal (0.8-1.2x), high (>1.2x)
   - RSI: oversold (<30), neutral (30-70), overbought (>70)

4. **Temporal Consistency (10%)**: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö?
   - "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏£‡πà‡∏ß‡∏á‡∏°‡∏≤ 3 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô" ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡πÅ‡∏Ñ‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‚Üí ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
   - "‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏ô" ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö ‚Üí ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö

**‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (FaithfulnessScorer ‡∏ó‡∏≥‡πÅ‡∏•‡πâ‡∏ß):**
- ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡πÄ‡∏ä‡πà‡∏ô RSI = 45 vs 47)
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏õ‡∏±‡∏î‡πÄ‡∏®‡∏© (‡πÄ‡∏ä‡πà‡∏ô 1.28% vs 1.2814%)
- ‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

**‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô:**
- 90-100 = ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏•‡∏¢ ‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
- 75-89 = ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ 1-2 ‡∏à‡∏∏‡∏î
- 60-74 = ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á 3-4 ‡∏à‡∏∏‡∏î
- 40-59 = ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢‡∏à‡∏∏‡∏î 5+ ‡∏à‡∏∏‡∏î
- 0-39 = ‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á

**‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON:**
{
    "score": 0-100,
    "confidence": 0-100,
    "inconsistencies": ["‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á"],
    "validated_alignments": ["‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"],
    "reasoning": "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô"
}"""

    def __init__(self, model: str = "gpt-4o-mini", temperature: float = 0.0):
        """
        Initialize consistency scorer

        Args:
            model: OpenAI model to use (default: gpt-4o-mini for cost efficiency)
            temperature: LLM temperature (default: 0.0 for deterministic output)
        """
        # Ensure model has openai/ prefix for OpenRouter
        model_name = f"openai/{model}" if not model.startswith("openai/") else model
        # Support both OPENROUTER_API_KEY and OPENAI_API_KEY env vars
        api_key = os.getenv("OPENROUTER_API_KEY") or os.getenv("OPENAI_API_KEY")
        self.llm = ChatOpenAI(
            model=model_name,
            temperature=temperature,
            base_url="https://openrouter.ai/api/v1",
            api_key=api_key
        )
        self.model = model
        logger.info(f"ConsistencyScorer initialized with model={model_name}, temperature={temperature}")

    def score_narrative(
        self,
        narrative: str,
        indicators: Dict[str, Any],
        percentiles: Dict[str, Any],
        market_conditions: Dict[str, Any],
        ticker_data: Optional[Dict[str, Any]] = None
    ) -> ConsistencyResult:
        """
        Score narrative for logical consistency.

        Args:
            narrative: Generated Thai narrative text
            indicators: Technical indicators (RSI, MACD, SMA, etc.)
            percentiles: Percentile data for historical context
            market_conditions: Market metrics (uncertainty_score, atr_pct, volume_ratio, etc.)
            ticker_data: Optional company data for context

        Returns:
            ConsistencyResult with overall score and dimension breakdowns
        """
        try:
            # Build context for LLM
            context = {
                "indicators": indicators,
                "percentiles": percentiles,
                "market_conditions": market_conditions
            }
            if ticker_data:
                context["ticker_data"] = ticker_data

            context_json = json.dumps(context, indent=2, ensure_ascii=False)

            # Build prompt
            user_prompt = f"""**‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö:**
{narrative}

**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì (Ground Truth Data):**
```json
{context_json}
```

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô (interpretations) ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
‡πÇ‡∏î‡∏¢‡πÄ‡∏ô‡πâ‡∏ô‡∏ó‡∏µ‡πà:
1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
2. ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏Å‡∏±‡∏ô‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
3. ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
4. ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡∏≠‡∏¢‡πà‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (‡∏õ‡∏±‡∏î‡πÄ‡∏®‡∏© ¬±2% ‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ) ‡πÅ‡∏ï‡πà‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤**‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°**‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"""

            # Call LLM
            messages = [
                SystemMessage(content=self.SYSTEM_PROMPT),
                HumanMessage(content=user_prompt)
            ]

            response = self.llm.invoke(messages)

            # Parse JSON response
            response_text = response.content.strip()

            # Extract JSON if wrapped in markdown
            if "```json" in response_text:
                response_text = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                response_text = response_text.split("```")[1].split("```")[0].strip()

            result_dict = json.loads(response_text)

            # Extract dimension scores (LLM provides overall, we calculate dimensions)
            overall_score = result_dict.get("score", 0)
            confidence = result_dict.get("confidence", 0)
            inconsistencies = result_dict.get("inconsistencies", [])
            validated_alignments = result_dict.get("validated_alignments", [])
            reasoning = result_dict.get("reasoning", "")

            # Calculate dimension scores based on inconsistency count
            # (simplified heuristic - can be enhanced)
            inconsistency_count = len(inconsistencies)

            dimension_scores = {
                "logical_consistency": max(0, 100 - inconsistency_count * 10),
                "internal_consistency": 100 if inconsistency_count == 0 else max(0, 100 - inconsistency_count * 15),
                "semantic_consistency": max(0, 100 - inconsistency_count * 12),
                "temporal_consistency": 100 if inconsistency_count == 0 else max(0, 100 - inconsistency_count * 8)
            }

            return ConsistencyResult(
                overall_score=overall_score,
                confidence=confidence,
                dimension_scores=dimension_scores,
                inconsistencies=inconsistencies,
                validated_alignments=validated_alignments,
                reasoning=reasoning
            )

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM response as JSON: {e}")
            logger.error(f"Response text: {response_text}")
            return ConsistencyResult(
                overall_score=50.0,  # Conservative middle score on error
                confidence=0.0,
                dimension_scores={},
                inconsistencies=["Failed to parse LLM response"],
                reasoning=f"JSON parsing error: {str(e)}"
            )

        except Exception as e:
            logger.error(f"Consistency scoring error: {e}")
            return ConsistencyResult(
                overall_score=50.0,  # Conservative middle score on error
                confidence=0.0,
                dimension_scores={},
                inconsistencies=["Scoring error occurred"],
                reasoning=f"Error: {str(e)}"
            )


if __name__ == "__main__":
    # Simple test
    scorer = ConsistencyScorer()

    test_narrative = """üìñ Story: ‡∏´‡∏∏‡πâ‡∏ô DBS Group ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏Ç‡∏≤‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏£‡∏á‡∏î‡πâ‡∏ß‡∏¢ RSI ‡∏ó‡∏µ‡πà 25 ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡∏±‡∏°‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å

üí° Insights: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏±‡∏ô‡∏ú‡∏ß‡∏ô‡∏ï‡πà‡∏≥‡∏°‡∏≤‡∏Å ATR 0.5% ‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å"""

    test_indicators = {
        "rsi": 25,
        "current_price": 53.74,
        "sma_20": 53.5,
        "sma_50": 52.2,
        "sma_200": 46.0
    }

    test_market_conditions = {
        "uncertainty_score": 55,
        "atr_pct": 0.5,
        "volume_ratio": 0.3,
        "price_vs_vwap_pct": 5.2
    }

    result = scorer.score_narrative(
        narrative=test_narrative,
        indicators=test_indicators,
        percentiles={},
        market_conditions=test_market_conditions
    )

    print(f"\n=== Consistency Test ===")
    print(f"Score: {result.overall_score}/100")
    print(f"Confidence: {result.confidence}/100")
    print(f"\nInconsistencies found: {len(result.inconsistencies)}")
    for inc in result.inconsistencies:
        print(f"  - {inc}")
    print(f"\nValidated alignments: {len(result.validated_alignments)}")
    for val in result.validated_alignments:
        print(f"  - {val}")
    print(f"\nReasoning: {result.reasoning}")
